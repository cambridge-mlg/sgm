{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from jax import random\n",
    "import optax\n",
    "import wandb\n",
    "from ml_collections import config_dict\n",
    "\n",
    "import src.models as models\n",
    "from src.models import make_VAE_loss, make_VAE_eval\n",
    "from src.data import get_image_dataset, NumpyLoader, METADATA\n",
    "from src.utils.training import TrainState, train_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'train_vae.ipynb'\n",
    "# ^ W&B doesn't know how to handle VS Code notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_dict.ConfigDict()\n",
    "\n",
    "config.dataset_name = 'MNIST'\n",
    "config.val_percent = 0.1\n",
    "config.batch_size = 512\n",
    "\n",
    "config.learning_rate = 1e-4\n",
    "config.peak_learning_rate = 3 * config.learning_rate\n",
    "config.final_learning_rate = 0.1 * config.learning_rate\n",
    "config.peak_lr_percent = 0.2\n",
    "config.weight_decay = 1e-4\n",
    "config.epochs = 100\n",
    "\n",
    "config.model_name = 'VAE'\n",
    "config.model = config_dict.ConfigDict()\n",
    "config.model.latent_dim = 128\n",
    "config.model.learn_prior = False\n",
    "config.model.convolutional = True\n",
    "\n",
    "config.model.encoder = config_dict.ConfigDict()\n",
    "config.model.encoder.posterior = 'hetero-diag-normal'\n",
    "config.model.encoder.hidden_dims = [64, 128, 256]\n",
    "config.model.encoder.act_fn = 'gelu'\n",
    "\n",
    "config.model.decoder = config_dict.ConfigDict()\n",
    "config.model.decoder.likelihood = 'iso-normal'\n",
    "config.model.decoder.hidden_dims = list(reversed(config.model.encoder.hidden_dims))\n",
    "# config.model.decoder.hidden_dims = [32, 64, 128]\n",
    "config.model.decoder.act_fn = 'gelu'\n",
    "config.model.decoder.image_shape = METADATA['image_shape'][config.dataset_name]\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for annoying \"WARNING:root:The use of `check_types` is deprecated and does not have any effect.\"\n",
    "# error message produced by tfp.\n",
    "logger = logging.getLogger('root')\n",
    "\n",
    "class CheckTypesFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return 'check_types' not in record.getMessage()\n",
    "\n",
    "logger.addFilter(CheckTypesFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, val_dataset = get_image_dataset(\n",
    "    dataset_name=config.dataset_name,\n",
    "    val_percent=config.val_percent,\n",
    "    flatten_img=not config.model.convolutional,\n",
    ")\n",
    "train_loader = NumpyLoader(train_dataset, config.batch_size)\n",
    "val_loader = NumpyLoader(val_dataset, config.batch_size)\n",
    "test_loader = NumpyLoader(test_dataset, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = getattr(models, config.model_name)\n",
    "model = model_cls(**config.model.to_dict())\n",
    "\n",
    "init_rng, rng = random.split(rng)\n",
    "init_data = train_dataset[0][0]\n",
    "variables = model.init(init_rng, init_data, rng)\n",
    "model_state, params = variables.pop('params')\n",
    "del variables\n",
    "\n",
    "total_steps = config.epochs * len(train_loader)\n",
    "lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "    init_value=config.learning_rate, peak_value=config.peak_learning_rate,\n",
    "    warmup_steps=int(total_steps * config.peak_lr_percent),\n",
    "    decay_steps=total_steps, end_value=config.final_learning_rate\n",
    ")\n",
    "\n",
    "state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=params,\n",
    "    tx=optax.adamw(lr_schedule, weight_decay=config.weight_decay),\n",
    "    model_state=model_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = train_loop(\n",
    "    model, state, config, rng, make_VAE_loss, make_VAE_eval, train_loader, val_loader,\n",
    "    # test_loader,\n",
    "    # wandb_kwargs={'mode': 'offline'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85696cc8f8f812d4e53cfd8a6f4960223adf32f47c94bbc41d022414b9401ed4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('inv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
